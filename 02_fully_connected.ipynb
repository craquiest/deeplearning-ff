{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"02_fully_connected.ipynb","provenance":[{"file_id":"https://github.com/fastai/course-v3/blob/master/nbs/dl2/02_fully_connected.ipynb","timestamp":1565039924193}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xtijgnz9gId5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"ef507d99-cbeb-4abb-a602-65ff1cd384b2","executionInfo":{"status":"ok","timestamp":1570647209872,"user_tz":-60,"elapsed":3276,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","from google.colab import drive\n","import sys, os, shutil\n","from pathlib import Path\n","drive.mount(\"/content/drive\", force_remount=True); my_drive = Path('/content/drive/My Drive/');\n","colabase = my_drive/'Colab Notebooks/'; course = my_drive/'github/fastai_course-v3/'\n","dlff = my_drive/'deeplearning-ff/'; pkl_path= dlff/'pickles'\n","os.chdir(dlff) #sys.path.append(str(dlff)) # cd {dlff}"],"execution_count":87,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uX-pdXrApcow","colab_type":"text"},"source":["## The forward and backward passes"]},{"cell_type":"markdown","metadata":{"id":"1hwuI2W3pcox","colab_type":"text"},"source":["[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=4960)"]},{"cell_type":"code","metadata":{"id":"J4yfH6G8pcoy","colab_type":"code","colab":{}},"source":["#export\n","from exports.lg_01 import *\n","\n","def get_data():\n","    path = datasets.download_data(MNIST_URL, ext='.gz')\n","    with gzip.open(path, 'rb') as f:\n","        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n","    return map(tensor, (x_train,y_train,x_valid,y_valid))\n","\n","def normalize(x, m, s): return (x-m)/s"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMkmD-fQpco2","colab_type":"code","colab":{}},"source":["x_train,y_train,x_valid,y_valid = get_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"COPdIOaHpco5","colab_type":"code","outputId":"2e4e009a-9a61-4f44-beae-1a6898813bc7","executionInfo":{"status":"ok","timestamp":1570647212126,"user_tz":-60,"elapsed":5381,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_mean,train_std = x_train.mean(),x_train.std()\n","train_mean,train_std"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.1304), tensor(0.3073))"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"WCBlz1MCpco-","colab_type":"code","colab":{}},"source":["x_train = normalize(x_train, train_mean, train_std)\n","# NB: Use training, not validation mean for validation set\n","x_valid = normalize(x_valid, train_mean, train_std)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TJieuGYpcpB","colab_type":"code","outputId":"8f533bf3-0e61-4e8a-8edb-dfd3201088c2","executionInfo":{"status":"ok","timestamp":1570647212531,"user_tz":-60,"elapsed":5587,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_mean,train_std = x_train.mean(),x_train.std()\n","train_mean,train_std"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.0001), tensor(1.))"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"_pxSZmy0pcpF","colab_type":"code","colab":{}},"source":["#export\n","def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zdnlJ-rSpcpK","colab_type":"code","colab":{}},"source":["test_near_zero(x_train.mean())\n","test_near_zero(1-x_train.std())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SFo1NxSEpcpO","colab_type":"code","outputId":"8ff7aee9-7a67-494e-9d29-fd149648813a","executionInfo":{"status":"ok","timestamp":1570647212533,"user_tz":-60,"elapsed":5519,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["n,m = x_train.shape\n","c = y_train.max()+1\n","n,m,c"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 784, tensor(10))"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"markdown","metadata":{"id":"ER_o5kYHpcpR","colab_type":"text"},"source":["## Foundations version"]},{"cell_type":"markdown","metadata":{"id":"4eR_eWdbpcpS","colab_type":"text"},"source":["### Basic architecture"]},{"cell_type":"markdown","metadata":{"id":"j5FuGpN7pcpT","colab_type":"text"},"source":["[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"]},{"cell_type":"code","metadata":{"id":"qLZVHE8NpcpU","colab_type":"code","colab":{}},"source":["# num hidden\n","nh = 50"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s1niCvQlpcpY","colab_type":"text"},"source":["[Tinker practice](https://course.fast.ai/videos/?lesson=8&t=5255)"]},{"cell_type":"code","metadata":{"id":"x0EMzPz0pcpZ","colab_type":"code","colab":{}},"source":["# simplified kaiming init / he init\n","w1 = torch.randn(m,nh)/math.sqrt(m)\n","b1 = torch.zeros(nh)\n","w2 = torch.randn(nh,1)/math.sqrt(nh)\n","b2 = torch.zeros(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKGwH-ENpcpc","colab_type":"code","colab":{}},"source":["test_near_zero(w1.mean())\n","test_near_zero(w1.std()-1/math.sqrt(m))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2nieWrOpcph","colab_type":"code","outputId":"63378199-00bf-4d4a-d1f2-0ae8df1523c3","executionInfo":{"status":"ok","timestamp":1570647212954,"user_tz":-60,"elapsed":5806,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# This should be ~ (0,1) (mean,std)...\n","x_valid.mean(),x_valid.std()"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-0.0057), tensor(0.9924))"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"id":"g2vzh6tspcpm","colab_type":"code","colab":{}},"source":["#export\n","def lin_man(x, w, b): \n","  \"\"\"Manual linear transform\"\"\"\n","  return x@w + b "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bl08Nu1pcpu","colab_type":"code","colab":{}},"source":["t = lin_man(x_valid, w1, b1)\n","# with this, each elt of matrix is a sum of m elts \n","# for the sake of arg, if u say indep stdnorm, var = m * var_i so stdev = sqrt(m) * stdev_i\n","# so we have to divide by sqrt(m)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6OLnw8Epcpx","colab_type":"code","outputId":"4cbf87a2-c7d5-4a55-d731-2f3891474472","executionInfo":{"status":"ok","timestamp":1570647212959,"user_tz":-60,"elapsed":5682,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#...so should this, because we used kaiming init, which is designed to do this\n","t.mean(),t.std()"],"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-0.1839), tensor(0.9872))"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"id":"fWzCrKGmpcp0","colab_type":"code","colab":{}},"source":["def relu_man(x): \n","  \"\"\"Manual ReLU function \"\"\"\n","  return x.clamp_min(0.)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uatfztl1pcp4","colab_type":"code","colab":{}},"source":["t = relu_man(lin_man(x_valid, w1, b1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qM3iUn3Opcp8","colab_type":"code","outputId":"76b69cf9-1400-4582-c3b7-5804e25fa721","executionInfo":{"status":"ok","timestamp":1570647212961,"user_tz":-60,"elapsed":5518,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#...actually it really should be this!\n","t.mean(),t.std()"],"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.3007), tensor(0.5135))"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"markdown","metadata":{"id":"EoJuN3IrpcqE","colab_type":"text"},"source":["From pytorch docs: `a: the negative slope of the rectifier used after this layer (0 for ReLU by default)`\n","\n","$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n","\n","This was introduced in the paper that described the Imagenet-winning approach from *He et al*: [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852), which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)"]},{"cell_type":"markdown","metadata":{"id":"dFwjuw55pcqG","colab_type":"text"},"source":["[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"]},{"cell_type":"code","metadata":{"id":"Ub-Bdn2KpcqH","colab_type":"code","colab":{}},"source":["# kaiming init / he init for relu\n","w1 = torch.randn(m,nh)*math.sqrt(2/m)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsUhNU1AepCS","colab_type":"code","colab":{}},"source":["# export\n","def kaiming_init(m,nh): \n","  \"\"\"Scratch Kaiming He init. Use as w1 = kaiming_init(m,nh)\"\"\"\n","  return torch.randn(m,nh)*math.sqrt(2./m)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWAujEnZpcqK","colab_type":"code","outputId":"97be2bf8-9ef2-47ed-affb-644967c581b4","executionInfo":{"status":"ok","timestamp":1570647212963,"user_tz":-60,"elapsed":5475,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["w1 = kaiming_init(m,nh)\n","w1.mean(),w1.std()"],"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.0006), tensor(0.0507))"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"id":"Kq6_p6hFpcqN","colab_type":"code","outputId":"2b95f87e-edff-4d50-9aae-676a8aee0b50","executionInfo":{"status":"ok","timestamp":1570647212964,"user_tz":-60,"elapsed":5462,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["t = relu_man(lin_man(x_valid, w1, b1))\n","t.mean(),t.std()"],"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.5791), tensor(0.8557))"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"code","metadata":{"id":"h9U0X8MCpcqR","colab_type":"code","colab":{}},"source":["#export\n","from torch.nn import init"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Za9KrJzapcqV","colab_type":"code","colab":{}},"source":["w1 = torch.zeros(m,nh)\n","init.kaiming_normal_(w1, mode='fan_out') #normally fan_in to keep unit var of fwd pass. see below\n","t = relu_man(lin_man(x_valid, w1, b1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxpAAiZapcqX","colab_type":"code","colab":{}},"source":["init.kaiming_normal_??"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sS9IiWQspcqj","colab_type":"code","outputId":"b4cd3394-c195-4bf8-cb57-8322628c0074","executionInfo":{"status":"ok","timestamp":1570647213707,"user_tz":-60,"elapsed":6047,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["w1.mean(),w1.std()"],"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-7.0117e-06), tensor(0.0504))"]},"metadata":{"tags":[]},"execution_count":113}]},{"cell_type":"code","metadata":{"id":"bzOA_GcJpcqm","colab_type":"code","outputId":"b70cbafe-e3b4-45b3-ef95-9790c2afe712","executionInfo":{"status":"ok","timestamp":1570647213708,"user_tz":-60,"elapsed":6014,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["t.mean(),t.std()"],"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.5542), tensor(0.8103))"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"code","metadata":{"id":"bQBWCbkPpcqo","colab_type":"code","outputId":"303851dd-261e-49ab-8223-fab4f496fbc5","executionInfo":{"status":"ok","timestamp":1570647213708,"user_tz":-60,"elapsed":5979,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["w1.shape"],"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([784, 50])"]},"metadata":{"tags":[]},"execution_count":115}]},{"cell_type":"code","metadata":{"id":"6HDPVGDlpcqs","colab_type":"code","colab":{}},"source":["import torch.nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9UZv0Yrpcqv","colab_type":"code","outputId":"f5948947-5a86-4a56-8811-7d46cdc5877c","executionInfo":{"status":"ok","timestamp":1570647213709,"user_tz":-60,"elapsed":5869,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.nn.Linear(m,nh).weight.shape # there is a transpose inside the pytorch Linear output = input.matmul(weight.t())\n","# thats why we use fan_out io fan_in ( we are 'tricking' the funcs to get unit var fwd pass)"],"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([50, 784])"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uqK-Zx_hl1Bm","colab":{}},"source":["torch.nn.Linear.forward??"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYCiFv4tpcq1","colab_type":"code","colab":{}},"source":["torch.nn.functional.linear??\n","# F.linear means this F = torch.nn.functional; torch.nn.Linear calls F.linear"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2B1kh1Jpcq4","colab_type":"code","colab":{}},"source":["torch.nn.Conv2d??"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1xjTZLXpcq8","colab_type":"code","colab":{}},"source":["torch.nn.modules.conv._ConvNd.reset_parameters??\n","# whats with the sqrt(5)?"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"brK93Ftwpcq-","colab_type":"code","colab":{}},"source":["#export\n","def relu_tweak(x): \n","  \"\"\"Tweaked ReLU: what if we substract 0.5 to get relu mean to 0\"\"\"\n","  return x.clamp_min(0.) - 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6t7K-hyIpcrF","colab_type":"code","outputId":"d3c1c2b8-3663-4307-99e8-f23a99f963a8","executionInfo":{"status":"ok","timestamp":1570647214347,"user_tz":-60,"elapsed":6417,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# kaiming init / he init for relu\n","# w1 = torch.randn(m,nh)*math.sqrt(2./m )\n","w1 = kaiming_init(m,nh)\n","t1 = relu_tweak(lin_man(x_valid, w1, b1))\n","t1.mean(),t1.std()"],"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-0.0272), tensor(0.7588))"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"id":"wAA2_iQHpcrI","colab_type":"code","colab":{}},"source":["def model(xb):\n","    l1 = lin_man(xb, w1, b1)\n","    l2 = relu_tweak(l1)\n","    l3 = lin_man(l2, w2, b2)\n","    return l3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQxYtnEDpcrL","colab_type":"code","outputId":"c52ecac2-9539-4895-f25e-379ad597292a","executionInfo":{"status":"ok","timestamp":1570647214353,"user_tz":-60,"elapsed":6354,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%timeit -n 10 _=model(x_valid)"],"execution_count":125,"outputs":[{"output_type":"stream","text":["10 loops, best of 3: 19.6 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wn0XbSYGpcrO","colab_type":"code","colab":{}},"source":["assert model(x_valid).shape==torch.Size([x_valid.shape[0],1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZrSRL8FapcrQ","colab_type":"text"},"source":["### Loss function: MSE"]},{"cell_type":"markdown","metadata":{"id":"ISQ6yW8TpcrR","colab_type":"text"},"source":["[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6372)"]},{"cell_type":"code","metadata":{"id":"89U49GjfpcrS","colab_type":"code","outputId":"65b5cc35-0485-45a2-f18d-420122a291f7","executionInfo":{"status":"ok","timestamp":1570647215063,"user_tz":-60,"elapsed":7021,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model(x_valid).shape"],"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000, 1])"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"markdown","metadata":{"id":"8ITi7DuApcrV","colab_type":"text"},"source":["We need `squeeze()` to get rid of that trailing (,1), in order to use `mse`. (Of course, `mse` is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use `mse` for now to keep things simple.)"]},{"cell_type":"code","metadata":{"id":"vSwR_qmWpcrW","colab_type":"code","colab":{}},"source":["#export\n","def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4xXhpUIpcra","colab_type":"code","colab":{}},"source":["y_train,y_valid = y_train.float(),y_valid.float()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GwkcNrI3pcrk","colab_type":"code","colab":{}},"source":["preds = model(x_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JvE1E3Rupcrm","colab_type":"code","outputId":"e77a65b0-6418-44c3-d25f-23a231d6481c","executionInfo":{"status":"ok","timestamp":1570647215069,"user_tz":-60,"elapsed":6846,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["preds.shape"],"execution_count":131,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([50000, 1])"]},"metadata":{"tags":[]},"execution_count":131}]},{"cell_type":"code","metadata":{"id":"u0jjEcp7pcrr","colab_type":"code","outputId":"0e38b0c7-11cc-4f10-93b3-9a95d065cd46","executionInfo":{"status":"ok","timestamp":1570647215070,"user_tz":-60,"elapsed":6820,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mse(preds, y_train)"],"execution_count":132,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(28.7992)"]},"metadata":{"tags":[]},"execution_count":132}]},{"cell_type":"markdown","metadata":{"id":"h5ZSebQ0pcr0","colab_type":"text"},"source":["### Gradients and backward pass"]},{"cell_type":"markdown","metadata":{"id":"wbdEg7Snpcr3","colab_type":"text"},"source":["[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6493)"]},{"cell_type":"code","metadata":{"id":"TizWMxM_pcr4","colab_type":"code","colab":{}},"source":["#export\n","def mse_grad(inp, targ): \n","    # grad of loss with respect to output of previous layer; \n","    # inp here is 'out' of relu; so we store the grad there to pass it through, and use chain rule\n","    # this is dMSE / dyhat \n","    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]\n","    # 2/N (yhat-y); yhat is inp, inp/shape is N (numb classes/dim output) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-FW0E4hpcr6","colab_type":"code","colab":{}},"source":["#export\n","def relu_grad(inp, out):\n","    # grad of relu with respect to input activations\n","    # this is dRelu(z)/dz * dMSE/dRelu: accumulating chain rule\n","    inp.g = (inp>0).float() * out.g \n","    # out.g contains inp.g from mse_grad stored by mse_grad\n","    # inp.g is stored for lin_grad"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_BCtb0BLpcr7","colab_type":"code","colab":{}},"source":["#export\n","def lin_grad(inp, out, w, b):\n","    # grad of matmul with respect to input,weight and biase\n","    inp.g = out.g @ w.t()     # grad of matrix prod = matri prod with transpose\n","    # Creating a giant outer product, just to sum it, is inefficient!\n","    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0) #sum over training examples (1/m baked in from mse_grad)\n","    b.g = out.g.sum(0) #sum over training examples (1/m baked in from mse_grad)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0zUWYHfpcr9","colab_type":"code","colab":{}},"source":["#export\n","def forward_and_backward(inp, targ):\n","    # forward pass:\n","    l1 = inp @ w1 + b1\n","    l2 = relu_tweak(l1)\n","    out = l2 @ w2 + b2\n","    # we don't actually need the loss in backward!\n","    loss = mse(out, targ)\n","    \n","    # backward pass:\n","    mse_grad(out, targ)\n","    lin_grad(l2, out, w2, b2) # out.g contains grad of next layer\n","    relu_grad(l1, l2)         # l2.g contains grad of next layer\n","    lin_grad(inp, l1, w1, b1) # l1.g contains grad of next layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEEslgFZpcr_","colab_type":"code","colab":{}},"source":["forward_and_backward(x_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I94IIWXVpcsB","colab_type":"code","colab":{}},"source":["# Save for testing against later\n","w1g = w1.g.clone()\n","w2g = w2.g.clone()\n","b1g = b1.g.clone()\n","b2g = b2.g.clone()\n","ig  = x_train.g.clone()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mFTKHmEgpcsF","colab_type":"text"},"source":["We cheat a little bit and use PyTorch autograd to check our results."]},{"cell_type":"code","metadata":{"id":"Gjm3jNhJpcsG","colab_type":"code","colab":{}},"source":["xt2 = x_train.clone().requires_grad_(True)\n","w12 = w1.clone().requires_grad_(True)\n","w22 = w2.clone().requires_grad_(True)\n","b12 = b1.clone().requires_grad_(True)\n","b22 = b2.clone().requires_grad_(True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmWP6DVNpcsK","colab_type":"code","colab":{}},"source":["def forward(inp, targ):\n","    # forward pass:\n","    l1 = inp @ w12 + b12\n","    l2 = relu_tweak(l1)\n","    out = l2 @ w22 + b22\n","    # we don't actually need the loss in backward!\n","    return mse(out, targ)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KgGLxnIpcsP","colab_type":"code","colab":{}},"source":["loss = forward(xt2, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kW-kJk5MpcsR","colab_type":"code","colab":{}},"source":["loss.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8d5zHxspcsT","colab_type":"code","colab":{}},"source":["test_near(w22.grad, w2g)\n","test_near(b22.grad, b2g)\n","test_near(w12.grad, w1g)\n","test_near(b12.grad, b1g)\n","test_near(xt2.grad, ig )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FsLjxxDGpcsW","colab_type":"text"},"source":["## Refactor model"]},{"cell_type":"markdown","metadata":{"id":"5QTqzCxhpcsW","colab_type":"text"},"source":["### Layers as classes"]},{"cell_type":"markdown","metadata":{"id":"XGWYndDDpcsX","colab_type":"text"},"source":["[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7112)"]},{"cell_type":"code","metadata":{"id":"7pK4RQB0pcsX","colab_type":"code","colab":{}},"source":["class Relu():\n","    def __call__(self, inp):\n","        self.inp = inp\n","        self.out = inp.clamp_min(0.)-0.5\n","        return self.out\n","    \n","    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"29-Fpns3pcsZ","colab_type":"code","colab":{}},"source":["class Lin():\n","    def __init__(self, w, b): self.w,self.b = w,b\n","        \n","    def __call__(self, inp):\n","        self.inp = inp\n","        self.out = inp@self.w + self.b\n","        return self.out\n","    \n","    def backward(self):\n","        self.inp.g = self.out.g @ self.w.t()\n","        # Creating a giant outer product, just to sum it, is inefficient!\n","        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n","        self.b.g = self.out.g.sum(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vIyh7yLSpcsb","colab_type":"code","colab":{}},"source":["class Mse():\n","    def __call__(self, inp, targ):\n","        self.inp = inp\n","        self.targ = targ\n","        self.out = (inp.squeeze() - targ).pow(2).mean()\n","        return self.out\n","    \n","    def backward(self):\n","        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4GDKb-Hpcse","colab_type":"code","colab":{}},"source":["class Model():\n","    def __init__(self, w1, b1, w2, b2):\n","        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n","        self.loss = Mse()\n","        \n","    def __call__(self, x, targ):\n","        for l in self.layers: x = l(x)\n","        return self.loss(x, targ)\n","    \n","    def backward(self):\n","        self.loss.backward()\n","        for l in reversed(self.layers): l.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y5b1FLPWpcsn","colab_type":"code","colab":{}},"source":["w1.g,b1.g,w2.g,b2.g = [None]*4\n","model = Model(w1, b1, w2, b2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYZ5iKRvpcso","colab_type":"code","outputId":"dd7edd4d-7a8c-44b9-bbc8-47d933b4422d","executionInfo":{"status":"ok","timestamp":1570647222201,"user_tz":-60,"elapsed":13565,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time loss = model(x_train, y_train)"],"execution_count":149,"outputs":[{"output_type":"stream","text":["CPU times: user 114 ms, sys: 0 ns, total: 114 ms\n","Wall time: 116 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DDK9epEHpcsr","colab_type":"code","outputId":"30903025-7261-49c7-9932-73a9b362c417","executionInfo":{"status":"ok","timestamp":1570647227146,"user_tz":-60,"elapsed":18499,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time model.backward()"],"execution_count":150,"outputs":[{"output_type":"stream","text":["CPU times: user 4.58 s, sys: 48 ms, total: 4.63 s\n","Wall time: 4.64 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GrYqKj3zpcsv","colab_type":"code","colab":{}},"source":["test_near(w2g, w2.g)\n","test_near(b2g, b2.g)\n","test_near(w1g, w1.g)\n","test_near(b1g, b1.g)\n","test_near(ig, x_train.g)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KmY3nSQlpcsw","colab_type":"text"},"source":["### Module.forward()"]},{"cell_type":"code","metadata":{"id":"FuhKwvocpcsx","colab_type":"code","colab":{}},"source":["class Module():\n","    def __call__(self, *args):\n","        self.args = args\n","        self.out = self.forward(*args)\n","        return self.out\n","    \n","    def forward(self): raise Exception('not implemented')\n","    def backward(self): self.bwd(self.out, *self.args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lFjLA4Ospcs3","colab_type":"code","colab":{}},"source":["class Relu(Module):\n","    def forward(self, inp): return inp.clamp_min(0.)-0.5\n","    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXp2CkWrpcs5","colab_type":"code","colab":{}},"source":["class Lin(Module):\n","    def __init__(self, w, b): self.w,self.b = w,b\n","        \n","    def forward(self, inp): return inp@self.w + self.b\n","    \n","    def bwd(self, out, inp):\n","        inp.g = out.g @ self.w.t()\n","        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n","        self.b.g = out.g.sum(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBNpN7gGpcs6","colab_type":"code","colab":{}},"source":["class Mse(Module):\n","    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n","    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BM_XlqULpcs8","colab_type":"code","colab":{}},"source":["class Model():\n","    def __init__(self):\n","        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n","        self.loss = Mse()\n","        \n","    def __call__(self, x, targ):\n","        for l in self.layers: x = l(x)\n","        return self.loss(x, targ)\n","    \n","    def backward(self):\n","        self.loss.backward()\n","        for l in reversed(self.layers): l.backward()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-rdo8U-pcs-","colab_type":"code","colab":{}},"source":["w1.g,b1.g,w2.g,b2.g = [None]*4\n","model = Model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"StG0ASrzpctA","colab_type":"code","outputId":"26361d63-06c3-4916-d6a4-c94bc2c8061e","executionInfo":{"status":"ok","timestamp":1570647228200,"user_tz":-60,"elapsed":19415,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time loss = model(x_train, y_train)"],"execution_count":158,"outputs":[{"output_type":"stream","text":["CPU times: user 113 ms, sys: 744 µs, total: 113 ms\n","Wall time: 113 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FFKj60Q8pctE","colab_type":"code","outputId":"827fc258-7cac-42b3-cf9a-05b31c73989c","executionInfo":{"status":"ok","timestamp":1570647228510,"user_tz":-60,"elapsed":19703,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time model.backward()"],"execution_count":159,"outputs":[{"output_type":"stream","text":["CPU times: user 229 ms, sys: 1.9 ms, total: 231 ms\n","Wall time: 231 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLdGyx4YpctH","colab_type":"code","colab":{}},"source":["test_near(w2g, w2.g)\n","test_near(b2g, b2.g)\n","test_near(w1g, w1.g)\n","test_near(b1g, b1.g)\n","test_near(ig, x_train.g)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95QhnCMzpctI","colab_type":"text"},"source":["### Without einsum"]},{"cell_type":"markdown","metadata":{"id":"dhHitEZ0pctJ","colab_type":"text"},"source":["[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7484)"]},{"cell_type":"code","metadata":{"id":"2Z0uqRBopctJ","colab_type":"code","colab":{}},"source":["class Lin(Module):\n","    def __init__(self, w, b): self.w,self.b = w,b\n","        \n","    def forward(self, inp): return inp@self.w + self.b\n","    \n","    def bwd(self, out, inp):\n","        inp.g = out.g @ self.w.t()\n","        self.w.g = inp.t() @ out.g #includes potentially summing over batch. \n","        # @ and matmult handle tensor of rank over 2.\n","        self.b.g = out.g.sum(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibXTbHMzpctL","colab_type":"code","colab":{}},"source":["w1.g,b1.g,w2.g,b2.g = [None]*4\n","model = Model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wJxw5RupctM","colab_type":"code","outputId":"43bea74c-7cd8-47d9-867d-66ad82bc7402","executionInfo":{"status":"ok","timestamp":1570647229932,"user_tz":-60,"elapsed":21060,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time loss = model(x_train, y_train)"],"execution_count":163,"outputs":[{"output_type":"stream","text":["CPU times: user 113 ms, sys: 681 µs, total: 114 ms\n","Wall time: 113 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2iu5zhyVpctR","colab_type":"code","outputId":"71a0611d-41d3-4d2c-94ee-fb12342d6b60","executionInfo":{"status":"ok","timestamp":1570647230250,"user_tz":-60,"elapsed":21361,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time model.backward()"],"execution_count":164,"outputs":[{"output_type":"stream","text":["CPU times: user 233 ms, sys: 1.93 ms, total: 235 ms\n","Wall time: 235 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mDIBVoyxpctY","colab_type":"code","colab":{}},"source":["test_near(w2g, w2.g)\n","test_near(b2g, b2.g)\n","test_near(w1g, w1.g)\n","test_near(b1g, b1.g)\n","test_near(ig, x_train.g)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"leIGjDOFpctb","colab_type":"text"},"source":["### nn.Linear and nn.Module"]},{"cell_type":"code","metadata":{"id":"nqVAQprUpctc","colab_type":"code","colab":{}},"source":["#export\n","from torch import nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nF20WTgQpcte","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","    def __init__(self, n_in, nh, n_out):\n","        super().__init__()\n","        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n","        self.loss = mse\n","        \n","    def __call__(self, x, targ):\n","        for l in self.layers: x = l(x)\n","        return self.loss(x.squeeze(), targ)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"za5JR-ITpctf","colab_type":"code","colab":{}},"source":["model = Model(m, nh, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gb48mYHopcth","colab_type":"code","outputId":"30858c2e-d7ac-47f5-abc5-256ea57df969","executionInfo":{"status":"ok","timestamp":1570647231425,"user_tz":-60,"elapsed":22454,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time loss = model(x_train, y_train)"],"execution_count":169,"outputs":[{"output_type":"stream","text":["CPU times: user 104 ms, sys: 0 ns, total: 104 ms\n","Wall time: 103 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RGG4_dAepctj","colab_type":"code","outputId":"8e06ab2b-1092-410e-d46e-5d59f50a52ac","executionInfo":{"status":"ok","timestamp":1570647231783,"user_tz":-60,"elapsed":22797,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%time loss.backward()"],"execution_count":170,"outputs":[{"output_type":"stream","text":["CPU times: user 79.6 ms, sys: 2.8 ms, total: 82.4 ms\n","Wall time: 81.7 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DueGYCx9pctl","colab_type":"text"},"source":["## Export"]},{"cell_type":"code","metadata":{"id":"Ak85KrcgadNK","colab_type":"code","outputId":"d57d519d-b57e-4e76-a36c-0e28a08a3928","executionInfo":{"status":"ok","timestamp":1570647235194,"user_tz":-60,"elapsed":26189,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!pip install fire"],"execution_count":171,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: fire in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PJ-NSsG-pctm","colab_type":"code","outputId":"862cc557-a2c4-41e3-8310-0947dc5854c3","executionInfo":{"status":"ok","timestamp":1570647236822,"user_tz":-60,"elapsed":27801,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["! python notebook2script.py 02_fully_connected.ipynb"],"execution_count":172,"outputs":[{"output_type":"stream","text":["Converted 02_fully_connected.ipynb to exports/lg_02.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sjeke3kc6olJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}