
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: deeplearning-ff/08_data_block.ipynb

from exports.lg_07a import *

import PIL, os, mimetypes
from collections import OrderedDict
import math

Path.ls = lambda x: list(x.iterdir())  #quickly add shortcut method to Path class

image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/')) #image extensions

def setify(o): return o if isinstance(o,set) else set(listify(o))
# fastest way to check if sth is in list is to turn into set

def _get_files(p, fs, extensions=None):
    """Get files with given extensions"""
    p = Path(p) # if not Path turn into Path
    res = [p/f for f in fs if not f.startswith('.')
           and ((not extensions) or f'.{f.split(".")[-1].lower()}' in extensions)]
    return res

def get_files(path, extensions=None, recurse=False, include=None):
    """Get files from a path, with certain extensions, recursively/not,
    optionnaly only include certain names."""
    path = Path(path)
    extensions = setify(extensions)
    extensions = {e.lower() for e in extensions}
    if recurse:
        res = []
        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)
            if include is not None and i==0: d[:] = [o for o in d if o in include]
            else:                            d[:] = [o for o in d if not o.startswith('.')]
            res += _get_files(p, f, extensions)
        return res
    else:
        f = [o.name for o in os.scandir(path) if o.is_file()]
        return _get_files(path, f, extensions)

def compose(x, funcs, *args, order_key='_order', **kwargs):
    """Successively pass x into pipe of functions: f1(f2(f3(f4(...fn(x)))))"""
    key = lambda o: getattr(o, order_key, 0)
    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)
    return x

class ItemList(ListContainer):
    """Superclass to override for various types of files.
    Give it items, a path, and transfroms to apply """

    def __init__(self, items, path='.', tfms=None):
        super().__init__(items)
        self.path,self.tfms = Path(path),tfms

    def __repr__(self): #also print path
      return f'{super().__repr__()}\nPath: {self.path}'

    def new(self, items, cls=None):
        # calls constructor; called by SplitData.split_by_func()
        if cls is None: cls=self.__class__
        return cls(items, self.path, tfms=self.tfms)

    def  get(self, i): return i # override this. base get
    def _get(self, i): return compose(self.get(i), self.tfms) # pass to transforms

    def __getitem__(self, idx): #impl. indexing
        res = super().__getitem__(idx)
        if isinstance(res,list): return [self._get(o) for o in res]
        return self._get(res)

class ImageList(ItemList):
    """Image type ItemList"""
    @classmethod
    def from_files(cls, path, extensions=None, recurse=True, include=None, **kwargs):
        if extensions is None: extensions = image_extensions
        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)

    def get(self, fn): return PIL.Image.open(fn)

class Transform(): _order=0 # base class with _order 0 by default

class MakeRGB(Transform):
    """Class version of transform"""
    def __call__(self, item): return item.convert('RGB')

def make_rgb(item):
  """Function version of transform"""
  return item.convert('RGB') #item needs to PIL.Image.open() obj

def grandparent_splitter(fn, valid_name='valid', train_name='train'):
    gp = fn.parent.parent.name
    return True if gp==valid_name else False if gp==train_name else None

def split_by_func(items, f):
    """Return two lists, depending to masks create for members of items by f,
    f in func that creates mask (ie list of True/False)"""
    mask = [f(o) for o in items]
    # `None` values will be filtered out
    faux = [o for o,m in zip(items,mask) if m==False]
    vrai = [o for o,m in zip(items,mask) if m==True ]
    return faux,vrai

class SplitData():
    def __init__(self, train, valid): self.train,self.valid = train,valid

    def __getattr__(self,k): return getattr(self.train,k)
    #This is needed if we want to pickle SplitData and be able to load it back without recursion errors
    def __setstate__(self,data:Any): self.__dict__.update(data)

    @classmethod
    def split_by_func(cls, il, f):
        lists = map(il.new, split_by_func(il.items, f))
        # applies ItemList.new() method to each list returned by split_by_func
        # which in turn calls constructor of ItemList; for same tupe, same transforms, same path
        # lists contains [train_il, valid_il]
        return cls(*lists)

    def __repr__(self): return f'{self.__class__.__name__}\nTrain: {self.train}\nValid: {self.valid}\n'


def uniqueify(x, sort=False):
    res = list(OrderedDict.fromkeys(x).keys())
    if sort: res.sort()
    return res

class Processor():
    def process(self, items): return items

class CategoryProcessor(Processor):
    """Give me items, i'll give you their int/label"""
    def __init__(self): self.vocab=None

    def __call__(self, items):
        #The vocab is defined on the first use.
        if self.vocab is None:
            #vocab not define so we define here
            self.vocab = uniqueify(items)
            # go from object to int with following dict; reverse mapping
            self.otoi  = {v:k for k,v in enumerate(self.vocab)}
        return [self.proc1(o) for o in items]
    def proc1(self, item):  return self.otoi[item] #get int from item

    def deprocess(self, idxs):
        assert self.vocab is not None
        return [self.deproc1(idx) for idx in idxs]
    def deproc1(self, idx): return self.vocab[idx] # get item from int

def parent_labeler(fn): return fn.parent.name

def _label_by_func(ds, f, cls=ItemList): return cls([f(o) for o in ds.items], path=ds.path)

#This is a slightly different from what was seen during the lesson,
#   we'll discuss the changes in lesson 11 (12?)
class LabeledData():
    def process(self, il, proc): return il.new(compose(il.items, proc))

    def __init__(self, x, y, proc_x=None, proc_y=None):
        self.x,self.y = self.process(x, proc_x),self.process(y, proc_y)
        self.proc_x,self.proc_y = proc_x,proc_y

    def __repr__(self): return f'{self.__class__.__name__}\nx: {self.x}\ny: {self.y}\n'
    def __getitem__(self,idx): return self.x[idx],self.y[idx]
    def __len__(self): return len(self.x)

    def x_obj(self, idx): return self.obj(self.x, idx, self.proc_x)
    def y_obj(self, idx): return self.obj(self.y, idx, self.proc_y)

    def obj(self, items, idx, procs):
        isint = isinstance(idx, int) or (isinstance(idx,torch.LongTensor) and not idx.ndim)
        item = items[idx]
        for proc in reversed(listify(procs)):
            item = proc.deproc1(item) if isint else proc.deprocess(item)
        return item

    @classmethod
    def label_by_func(cls, il, f, proc_x=None, proc_y=None):
        return cls(il, _label_by_func(il, f), proc_x=proc_x, proc_y=proc_y)

def label_by_func(sd, f, proc_x=None, proc_y=None):
    train = LabeledData.label_by_func(sd.train, f, proc_x=proc_x, proc_y=proc_y)
    valid = LabeledData.label_by_func(sd.valid, f, proc_x=proc_x, proc_y=proc_y)
    return SplitData(train,valid)

class ResizeFixed(Transform):
    _order=10 #Happens after RGB transf etc
    def __init__(self,size):
        if isinstance(size,int): size=(size,size) # make it tuple if not
        self.size = size

    def __call__(self, item):
      return item.resize(self.size, PIL.Image.BILINEAR) # type of resize

def to_byte_tensor(item):
    """Go from PIL to byte-Tensor, as in Torchvision"""
    res = torch.ByteTensor(torch.ByteStorage.from_buffer(item.tobytes()))
    w,h = item.size
    return res.view(h,w,-1).permute(2,0,1) # PIL has channel last, Pytorch has it fist
to_byte_tensor._order=20 # needs to happen after resizing, attach state to function

def to_float_tensor(item): return item.float().div_(255.) #div in place
to_float_tensor._order=30  # after tobyte_tensor

def show_image(im, figsize=(3,3)):
    plt.figure(figsize=figsize)
    plt.axis('off')
    plt.imshow(im.permute(1,2,0)) # need to put chanel last again

class DataBunch():
    def __init__(self, train_dl, valid_dl, c_in=None, c_out=None):
        """Contains dataloaders and datasets
        c_in and c_out to be used in model creation. """
        self.train_dl,self.valid_dl,self.c_in,self.c_out = train_dl,valid_dl,c_in,c_out

    @property
    def train_ds(self): return self.train_dl.dataset #direct access to ds from db

    @property
    def valid_ds(self): return self.valid_dl.dataset

def databunchify(sd, bs, c_in=None, c_out=None, **kwargs):
    """function that goes directly from the SplitData to a DataBunch"""
    dls = get_dls(sd.train, sd.valid, bs, **kwargs) #get dataloaders
    return DataBunch(*dls, c_in=c_in, c_out=c_out)

SplitData.to_databunch = databunchify # add (instance) method to Class SplitData

def normalize_chan(x, mean, std):
    """normalize by channel. Add 2 dimensions to make sure broadcasting works.
    Batch dimension will be padded in autom. in the front"""
    return (x-mean[...,None,None]) / std[...,None,None]

_m = tensor([0.47, 0.48, 0.45])
_s = tensor([0.29, 0.28, 0.30])
norm_imagenette = partial(normalize_chan, mean=_m.cuda(), std=_s.cuda())


def prev_pow_2(x):
    """What power of 2 is just before x """
    return 2**math.floor(math.log2(x))

def get_cnn_layers(data, nfs, layer, **kwargs):
    """Reutrns list of conv layers (incl BN, and Relu)"""
    def f(ni, nf, stride=2): return layer(ni, nf, 3, stride=stride, **kwargs)
    l1 = data.c_in # model knows #channel/inputs from the databach
    l2 = prev_pow_2(l1*3*3) # secound layer needs to be smaller pow of 2 than 27
    #that way, that layer is crunching info, not 'losing' any
    layers =  [f(l1  , l2  , stride=1),
               f(l2  , l2*2, stride=2),
               f(l2*2, l2*4, stride=2)]
    nfs = [l2*4] + nfs
    layers += [f(nfs[i], nfs[i+1]) for i in range(len(nfs)-1)]
    layers += [nn.AdaptiveAvgPool2d(1), Lambda(flatten),
               nn.Linear(nfs[-1], data.c_out)]
    return layers

def get_cnn_model(data, nfs, layer, **kwargs):
    """Returns nn.Sequential based on layer list from get_cnn_layers"""
    return nn.Sequential(*get_cnn_layers(data, nfs, layer, **kwargs))

def get_learn_run(nfs, data, lr, layer, cbs=None, opt_func=None, **kwargs):
    model = get_cnn_model(data, nfs, layer, **kwargs)
    init_cnn(model)
    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)

def model_summary(run, learn, data, find_all=False):
    """Defines hook and prints model arch by running one batch forward pass"""
    xb,yb = get_batch(data.valid_dl, run) #get one batch
    device = next(learn.model.parameters()).device#Model may not be on the GPU yet
    xb,yb = xb.to(device),yb.to(device)
    #recusive or not?--> find_all
    mods = find_modules(learn.model, is_lin_layer) if find_all else learn.model.children()
    f = lambda hook,mod,inp,out: print(f"{mod}\n{out.shape}\n")
    #quick hook on the fly, (hook + 3param) input;#hook will print module and out-shape
    with Hooks(mods, f) as hooks: learn.model(xb) #one forward pass on batch to activate/populate hooks