
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: deeplearning-ff/01_matmul.ipynb

from exports.lg_00 import *
import operator

from pathlib import Path
from IPython.core.debugger import set_trace
from fastai import datasets
import pickle, gzip, math, torch, matplotlib as mpl
import matplotlib.pyplot as plt
from torch import tensor

MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'


def test(a,b,cmp,cname=None):
    if cname is None: cname=cmp.__name__
    assert cmp(a,b),f"{cname}:\n{a}\n{b}"

def test_eq(a,b): test(a,b,operator.eq,'==')

def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)
def test_near(a,b): test(a,b,near)



def matmul_pureloops(a,b):
    """matmul with 3 loops, pure python"""
    ar,ac = a.shape # n_rows * n_cols
    br,bc = b.shape
    assert ac==br # check if mmult possible
    c = torch.zeros(ar, bc)
    for i in range(ar):
        for j in range(bc):
            for k in range(ac): # or br
                c[i,j] += a[i,k] * b[k,j]
    return c

def matmul_eltwise(a,b):
    """matmul with two loops, using element-wise mult"""
    ar,ac = a.shape
    br,bc = b.shape
    assert ac==br
    c = torch.zeros(ar, bc)
    for i in range(ar):
        for j in range(bc):
            # Any trailing ",:" can be removed
            c[i,j] = (a[i,:] * b[:,j]).sum()
    return c


def matmul_broadcast(a,b):
    """matmul with one loop, using broadcasting"""
    ar,ac = a.shape
    br,bc = b.shape
    assert ac==br
    c = torch.zeros(ar, bc)
    for i in range(ar):
        # c[i,j] = (a[i,:]          * b[:,j]).sum() # previous
        c[i]   = (a[i  ].unsqueeze(-1) * b).sum(dim=0)
    return c

def matmul_einstein(a,b):
  """matmul no loops, using Einstein summation"""
  # c[i,j] += a[i,k] * b[k,j]
  # c[i,j] = (a[i,:] * b[:,j]).sum()
  return torch.einsum('ik,kj->ij', a, b)