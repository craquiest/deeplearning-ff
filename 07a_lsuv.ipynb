{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"07a_lsuv.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"n3ZiWOVa8pSY","colab_type":"code","colab":{},"outputId":"deb4e4b7-e8e4-4bb9-ee0a-f0fbd9afb8f1"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XCN8bKfBFQ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e0e96334-c834-4285-9b88-0024658cd4d1","executionInfo":{"status":"ok","timestamp":1565636870141,"user_tz":-60,"elapsed":22172,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","from google.colab import drive\n","import sys, os, shutil\n","from pathlib import Path\n","drive.mount(\"/content/drive\", force_remount=True)\n","colabase = Path('/content/drive/My Drive/Colab Notebooks/')\n","course = Path('/content/drive/My Drive/course-v3/')\n","dlff = Path('/content/drive/My Drive/deeplearning-ff/')\n","#sys.path.append(str(dlff)) # cd {dlff}\n","os.chdir(dlff)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3DGLJB-C8pSg","colab_type":"code","colab":{}},"source":["#export\n","from exports.lg_07 import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jp804wnj8pSj","colab_type":"text"},"source":["## Layerwise Sequential Unit Variance (LSUV)"]},{"cell_type":"markdown","metadata":{"id":"3JM4if8E8pSk","colab_type":"text"},"source":["Getting the MNIST data and a CNN"]},{"cell_type":"markdown","metadata":{"id":"NDz0ZdGw8pSn","colab_type":"text"},"source":["[Jump_to lesson 11 video](https://course.fast.ai/videos/?lesson=11&t=235)"]},{"cell_type":"code","metadata":{"id":"WijTCO_o8pSo","colab_type":"code","colab":{}},"source":["x_train,y_train,x_valid,y_valid = get_data()\n","\n","x_train,x_valid = normalize_to(x_train,x_valid)\n","train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n","\n","nh,bs = 50,512\n","c = y_train.max().item()+1\n","loss_func = F.cross_entropy\n","\n","data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-J6e0eqC8pSs","colab_type":"code","colab":{}},"source":["mnist_view = view_tfm(1,28,28)\n","cbfs = [Recorder,\n","        partial(AvgStatsCallback,accuracy),\n","        CudaCallback,\n","        partial(BatchTransformXCallback, mnist_view)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ObRRlcOe8pSv","colab_type":"code","colab":{}},"source":["nfs = [8,16,32,64,64]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_I7aT2Oi8pSz","colab_type":"code","colab":{}},"source":["#export\n","class ConvLayer(nn.Module):\n","    def __init__(self, ni, nf, ks=3, stride=2, sub=0., **kwargs):\n","        super().__init__()\n","        self.conv = nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=True)\n","        self.relu = GeneralRelu(sub=sub, **kwargs)\n","    \n","    def forward(self, x): return self.relu(self.conv(x))\n","    \n","    @property\n","    def bias(self): return -self.relu.sub\n","    @bias.setter\n","    def bias(self,v): self.relu.sub = -v\n","    @property\n","    def weight(self): return self.conv.weight"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MmUJZF_8pS1","colab_type":"code","colab":{}},"source":["learn,run = get_learn_run(nfs, data, 0.6, ConvLayer, cbs=cbfs)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v0vB5ubI8pS4","colab_type":"text"},"source":["Now we're going to look at the paper [All You Need is a Good Init](https://arxiv.org/pdf/1511.06422.pdf), which introduces *Layer-wise Sequential Unit-Variance* (*LSUV*). We initialize our neural net with the usual technique, then we pass a batch through the model and check the outputs of the linear and convolutional layers. We can then rescale the weights according to the actual variance we observe on the activations, and subtract the mean we observe from the initial bias. That way we will have activations that stay normalized.\n","\n","We repeat this process until we are satisfied with the mean/variance we observe.\n","\n","Let's start by looking at a baseline:"]},{"cell_type":"code","metadata":{"id":"s1tXR-pw8pS5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"8b6141a7-59f7-48ea-9f36-57ac540bfa2c","executionInfo":{"status":"ok","timestamp":1565634101252,"user_tz":-60,"elapsed":10414,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["run.fit(2, learn)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["train: [2.18009921875, tensor(0.2583, device='cuda:0')]\n","valid: [1.16260751953125, tensor(0.5572, device='cuda:0')]\n","train: [0.561432890625, tensor(0.8212, device='cuda:0')]\n","valid: [0.2279136962890625, tensor(0.9286, device='cuda:0')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3WnSNCUV8pTA","colab_type":"text"},"source":["Now we recreate our model and we'll try again with LSUV. Hopefully, we'll get better results!"]},{"cell_type":"code","metadata":{"id":"Pbs-c61q8pTB","colab_type":"code","colab":{}},"source":["learn,run = get_learn_run(nfs, data, 0.6, ConvLayer, cbs=cbfs)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eCDWt02Q8pTE","colab_type":"text"},"source":["Helper function to get one batch of a given dataloader, with the callbacks called to preprocess it."]},{"cell_type":"code","metadata":{"id":"YN2P2ywN8pTF","colab_type":"code","colab":{}},"source":["#export\n","def get_batch(dl, run):\n","    run.xb,run.yb = next(iter(dl))\n","    for cb in run.cbs: cb.set_runner(run)\n","    run('begin_batch')\n","    return run.xb,run.yb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCypGCPt8pTI","colab_type":"code","colab":{}},"source":["xb,yb = get_batch(data.train_dl, run)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1wElT1d8pTM","colab_type":"text"},"source":["We only want the outputs of convolutional or linear layers. To find them, we need a recursive function. We can use `sum(list, [])` to concatenate the lists the function finds (`sum` applies the + operate between the elements of the list you pass it, beginning with the initial state in the second argument)."]},{"cell_type":"code","metadata":{"id":"UMpVSf628pTN","colab_type":"code","colab":{}},"source":["#export\n","def find_modules(m, cond):\n","    \"\"\"Find recursively modules satisfying a certain condition\n","    define condition as function, or lambda function\n","    >> mods = find_modules(learn.model, lambda o: isinstance(o,ConvLayer))\"\"\"\n","    if cond(m): return [m]\n","    return sum([find_modules(o,cond) for o in m.children()], [])\n","\n","def is_lin_layer(l):\n","    \"\"\"Condition function to find linear family layers\"\"\"\n","    lin_layers = (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear, nn.ReLU)\n","    return isinstance(l, lin_layers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uphcLEDG8pTQ","colab_type":"code","colab":{}},"source":["mods = find_modules(learn.model, lambda o: isinstance(o,ConvLayer))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpODiaLl8pTV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":294},"outputId":"a4c91534-02e1-4a49-dfb2-9fa64d80213f","executionInfo":{"status":"ok","timestamp":1565634408081,"user_tz":-60,"elapsed":425,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["mods"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[ConvLayer(\n","   (conv): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","   (relu): GeneralRelu()\n"," ), ConvLayer(\n","   (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","   (relu): GeneralRelu()\n"," ), ConvLayer(\n","   (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","   (relu): GeneralRelu()\n"," ), ConvLayer(\n","   (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","   (relu): GeneralRelu()\n"," ), ConvLayer(\n","   (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","   (relu): GeneralRelu()\n"," )]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"fuZELAJ_8pTZ","colab_type":"text"},"source":["This is a helper function to grab the mean and std of the output of a hooked layer."]},{"cell_type":"code","metadata":{"id":"b0Yl_pe_8pTa","colab_type":"code","colab":{}},"source":["def append_stat(hook, mod, inp, outp): #define a hook ie the f to pas to Hools(m,f)\n","    d = outp.data\n","    hook.mean,hook.std = d.mean().item(),d.std().item() # .item() to get float from tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIZAQQci8pTf","colab_type":"code","colab":{}},"source":["mdl = learn.model.cuda() #pop model to gpu"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yMZfrQDi8pTi","colab_type":"text"},"source":["So now we can look at the mean and std of the conv layers of our model."]},{"cell_type":"code","metadata":{"id":"yVCd-oNa8pTi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"0d5da97f-6526-4a7d-fa01-590795eecadf","executionInfo":{"status":"ok","timestamp":1565634784312,"user_tz":-60,"elapsed":466,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["with Hooks(mods, append_stat) as hooks: # hook context manager to use the hook\n","    mdl(xb) #run model to activate hooks\n","    for hook in hooks: print(hook.mean,hook.std) #hook your fruits"],"execution_count":19,"outputs":[{"output_type":"stream","text":["0.3802540898323059 0.6207240223884583\n","0.4048926532268524 0.6631969213485718\n","0.3998511731624603 0.6531000733375549\n","0.4170849025249481 0.6193254590034485\n","0.28708282113075256 0.45084869861602783\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DZLp2ZOe8pTm","colab_type":"text"},"source":["We first adjust the bias terms to make the means 0, then we adjust the standard deviations to make the stds 1 (with a threshold of 1e-3). The `mdl(xb) is not None` clause is just there to pass `xb` through `mdl` and compute all the activations so that the hooks get updated. "]},{"cell_type":"code","metadata":{"id":"TIU_9eA_8pTv","colab_type":"code","colab":{}},"source":["#export\n","def lsuv_module(m, xb):\n","    \"\"\"Apply LSUV init to each individual module using a hook\n","    Do with one batch, adjust bias and weight till you get 0 mean, 1 stdev\n","    >> for m in mods: print(lsuv_module(m, xb)) \"\"\"\n","    h = Hook(m, append_stat)\n","    \n","    while mdl(xb) is not None and abs(h.mean)  > 1e-3: \n","      m.bias -= h.mean # use bias property in ConLayer\n","    while mdl(xb) is not None and abs(h.std-1.0) > 1e-3:\n","      m.weight.data /= h.std # use weight property in ConLayer\n","\n","    h.remove() # dont forget to remove hook\n","    return h.mean,h.std "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2daj1-lP8pTz","colab_type":"text"},"source":["We execute that initialization on all the conv layers in order:"]},{"cell_type":"code","metadata":{"id":"BfsCAVaJJNE2","colab_type":"code","colab":{}},"source":["xb,yb = get_batch(data.train_dl, run)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzzD8h4W8pT0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"44046efe-0b79-418b-e53a-f6cd498ac0c5","executionInfo":{"status":"ok","timestamp":1565636154104,"user_tz":-60,"elapsed":608,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["for m in mods: print(lsuv_module(m, xb))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["(0.011186651885509491, 1.000272274017334)\n","(-0.186702162027359, 1.0000052452087402)\n","(-0.07696917653083801, 0.9994977116584778)\n","(-0.08315957337617874, 0.9999424815177917)\n","(-0.27443259954452515, 1.0002636909484863)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gGIO_TOb8pT5","colab_type":"text"},"source":["Note that the mean doesn't exactly stay at 0. since we change the standard deviation after by scaling the weight."]},{"cell_type":"markdown","metadata":{"id":"wbvkjA998pT5","colab_type":"text"},"source":["Then training is beginning on better grounds."]},{"cell_type":"code","metadata":{"id":"rW3k20kP8pT6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"9c6c8df7-0413-4549-e859-0be2cf767d8e","executionInfo":{"status":"ok","timestamp":1565636162254,"user_tz":-60,"elapsed":4595,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["%time run.fit(2, learn)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["train: [0.07616216796875, tensor(0.9769, device='cuda:0')]\n","valid: [0.07743304443359375, tensor(0.9761, device='cuda:0')]\n","train: [0.0500366162109375, tensor(0.9844, device='cuda:0')]\n","valid: [0.07615350341796875, tensor(0.9773, device='cuda:0')]\n","CPU times: user 2.84 s, sys: 1.2 s, total: 4.05 s\n","Wall time: 4.07 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yQTG7KRo8pT_","colab_type":"text"},"source":["LSUV is particularly useful for more complex and deeper architectures that are hard to initialize to get unit variance at the last layer."]},{"cell_type":"markdown","metadata":{"id":"M8lDwG4Z8pUA","colab_type":"text"},"source":["## Export"]},{"cell_type":"code","metadata":{"id":"CUSjfPyd8pUC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"da2329e6-fcb8-4deb-f9bd-e7574af6210b","executionInfo":{"status":"ok","timestamp":1565636878125,"user_tz":-60,"elapsed":2063,"user":{"displayName":"Lamine Gaye","photoUrl":"","userId":"14105741296786814762"}}},"source":["# !pip3 install fire\n","\n","!python notebook2script.py 07a_lsuv.ipynb"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Converted 07a_lsuv.ipynb to exports/lg_07a.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JrKUtrP38pUF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}